{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following notebook we are going to be **create a pipeline and model** for sentiment analysis on a collection of tweets about Apple Inc. After preprocessing, the tweets are labeled as either positive (i.e. I love the new iMac) or negative. (i.e. Apple has bad work poilicies!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "* Tweet Sentiment: Positive Sentiment = 1, Negative Sentiment = 0\n",
    "* Sentiment Confidence: Range of (0,1) describing the confidence of the sentiment assignment.\n",
    "* Text: Text composition of the tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.8468</td>\n",
       "      <td>top 3 all   tablets  damn right!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6736</td>\n",
       "      <td>cnbctv   apple's margins better than expected?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>wtf my battery was 31  one second ago and now ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>rt  bought my  at the  store  pretty good logo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>contact sync between yosemite and ios8 is ser...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  sentiment_confidence  \\\n",
       "0          1                0.8468   \n",
       "1          1                0.6736   \n",
       "2          0                1.0000   \n",
       "3          1                1.0000   \n",
       "4          0                1.0000   \n",
       "\n",
       "                                                text  \n",
       "0                  top 3 all   tablets  damn right!   \n",
       "1  cnbctv   apple's margins better than expected?...  \n",
       "2  wtf my battery was 31  one second ago and now ...  \n",
       "3  rt  bought my  at the  store  pretty good logo...  \n",
       "4   contact sync between yosemite and ios8 is ser...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('clean_apple.csv',encoding='latin-1',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.8468</td>\n",
       "      <td>top 3 all   tablets  damn right!</td>\n",
       "      <td>[top, 3, all, tablets, damn, right]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6736</td>\n",
       "      <td>cnbctv   apple's margins better than expected?...</td>\n",
       "      <td>[cnbctv, apple, s, margins, better, than, expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>wtf my battery was 31  one second ago and now ...</td>\n",
       "      <td>[wtf, my, battery, was, 31, one, second, ago, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>rt  bought my  at the  store  pretty good logo...</td>\n",
       "      <td>[rt, bought, my, at, the, store, pretty, good,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>contact sync between yosemite and ios8 is ser...</td>\n",
       "      <td>[contact, sync, between, yosemite, and, ios8, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  sentiment_confidence  \\\n",
       "0          1                0.8468   \n",
       "1          1                0.6736   \n",
       "2          0                1.0000   \n",
       "3          1                1.0000   \n",
       "4          0                1.0000   \n",
       "\n",
       "                                                text  \\\n",
       "0                  top 3 all   tablets  damn right!    \n",
       "1  cnbctv   apple's margins better than expected?...   \n",
       "2  wtf my battery was 31  one second ago and now ...   \n",
       "3  rt  bought my  at the  store  pretty good logo...   \n",
       "4   contact sync between yosemite and ios8 is ser...   \n",
       "\n",
       "                                              tokens  \n",
       "0                [top, 3, all, tablets, damn, right]  \n",
       "1  [cnbctv, apple, s, margins, better, than, expe...  \n",
       "2  [wtf, my, battery, was, 31, one, second, ago, ...  \n",
       "3  [rt, bought, my, at, the, store, pretty, good,...  \n",
       "4  [contact, sync, between, yosemite, and, ios8, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "## NLTK tokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')     ## This regular expression breaks a line into words\n",
    "df['tokens'] = df['text'].apply(tokenizer.tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X = df['text']\n",
    "y = df['sentiment']\n",
    "sent_confidence = df['sentiment_confidence']\n",
    "\n",
    "## We can see save the processed data if needed into a new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1236    for a limited time, the ibookstore is offering...\n",
      "1521    the hell does this mean  one day skype won't l...\n",
      "1315    why does  yosemite constantly restart due to a...\n",
      "31        what a joke! justice dept should prosecute k...\n",
      "938     rt  hey  how about you guys make a charger tha...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "## Splitting data for cross train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42) \n",
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vectorization of the training data with TFIDF and scikit learn\n",
    "\n",
    "vect = TfidfVectorizer()\n",
    "X_train_tfidf = vect.fit_transform(X_train)\n",
    "X_test_tfidf = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x2976 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vectorisation of the complete data for cross validation and training\n",
    "\n",
    "vect = TfidfVectorizer()\n",
    "X_tfidf = vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From spot checking algorithms and through cross validation and hyperparameter tuning we were able to find the best model for the dataset with the highest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn import svm'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.4s finished\n"
     ]
    }
   ],
   "source": [
    "model_best = svm.SVC(C=1, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=2, gamma=0.1, kernel='linear',\n",
    "                  max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001, verbose=False)\n",
    "\n",
    "model_best.fit(X_tfidf,y)\n",
    "prediction = cross_val_predict(model_best,X_tfidf,y, cv=10, verbose = 1,n_jobs =-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Classification Report for SVM: \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      1219\n",
      "           1       0.80      0.44      0.57       423\n",
      "\n",
      "    accuracy                           0.83      1642\n",
      "   macro avg       0.82      0.70      0.73      1642\n",
      "weighted avg       0.82      0.83      0.81      1642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y,prediction),cmap='summer',annot=True,fmt='2.0f')\n",
    "plt.show()\n",
    "print(\"\\n Classification Report for SVM: \\n \",classification_report(y,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removes special strings and non text\n",
    "\n",
    "class preprocess_text(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        if isinstance(X,pd.Series):\n",
    "            X = X.copy()\n",
    "            X = X.str.replace(r\"http\\S+\", \"\")\n",
    "            X = X.str.replace(r\"http\", \"\")\n",
    "            X = X.str.replace(r\"@\\S+\", \"\")\n",
    "            X = X.str.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "            X = X.str.replace(r\"@\", \"at\")\n",
    "            X = X.str.lower()\n",
    "            return X\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn import svm'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = Pipeline(verbose = True, steps = [('preprocessing', preprocess_text()),\n",
    "                         ('tfidf',TfidfVectorizer()),\n",
    "                          ('model', svm.SVC(C=1, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=2, gamma=0.1, kernel='linear',\n",
    "                                      max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001, verbose=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ..... (step 1 of 3) Processing preprocessing, total=   0.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............. (step 3 of 3) Processing model, total=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessing', preprocess_text()),\n",
       "                ('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('model',\n",
       "                 SVC(C=1, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=2,\n",
       "                     gamma=0.1, kernel='linear', max_iter=-1, probability=False,\n",
       "                     random_state=42, shrinking=True, tol=0.001,\n",
       "                     verbose=False))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_prediction = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[354  17]\n",
      " [ 51  71]]\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91       371\n",
      "           1       0.81      0.58      0.68       122\n",
      "\n",
      "    accuracy                           0.86       493\n",
      "   macro avg       0.84      0.77      0.79       493\n",
      "weighted avg       0.86      0.86      0.85       493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,pipe_prediction))\n",
    "print(\"\\n\\n\")\n",
    "print(classification_report(y_test,pipe_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(pd.Series(['Apple does work in a good manner']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    " \n",
    "pickle.dump(model_best, open('model.pkl', 'wb'))\n",
    "\n",
    "ml_model = pickle.load(open('model.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pipe, open('pipe.pkl','wb'))\n",
    "\n",
    "ml_pipe = pickle.load(open('pipe.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=2, gamma=0.1, kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix = \n",
      " [[1172   47]\n",
      " [ 235  188]]\n",
      "Accuracy of model =  0.8282582216808769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "prediction = cross_val_predict(ml_model,X_tfidf,y, cv=10, verbose = 1,n_jobs =-1)\n",
    " \n",
    "## Confusion matrix\n",
    "conf_mat = confusion_matrix(y, prediction)\n",
    "print('\\nConfusion matrix = \\n', conf_mat)\n",
    " \n",
    "## Accuracy\n",
    "print(\"Accuracy of model = \",metrics.accuracy_score(y, prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix = \n",
      " [[1156   63]\n",
      " [ 219  204]]\n",
      "Accuracy of model =  0.8282582216808769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.4s finished\n"
     ]
    }
   ],
   "source": [
    "prediction = cross_val_predict(ml_pipe,X,y, cv=10, verbose = 1,n_jobs =-1)\n",
    " \n",
    "## Confusion matrix\n",
    "conf_mat = confusion_matrix(y, prediction)\n",
    "print('\\nConfusion matrix = \\n', conf_mat)\n",
    " \n",
    "## Accuracy\n",
    "print(\"Accuracy of model = \",metrics.accuracy_score(y, prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We built a linear model that predicts the sentiment of tweets about Apple at around 83% accuracy. \n",
    "* The Confusion Matrix showed a tendency towards false negatives. Lastly we showed that the model succesfully inferred the importance of some english words to twitter sentiment.\n",
    "* More and better data is needed to improve the model accuracy and also reduce it's bias to negative tweets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
